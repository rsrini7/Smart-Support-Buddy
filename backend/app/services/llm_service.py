import logging
import requests
from fastapi import HTTPException
from app.core.config import settings

OPENROUTER_API_KEY = settings.OPENROUTER_API_KEY
OPENROUTER_API_URL = settings.OPENROUTER_API_URL
OPENROUTER_MODEL = settings.OPENROUTER_MODEL

# Recommended: Set your app's site URL and name for OpenRouter headers
YOUR_SITE_URL = settings.YOUR_SITE_URL
YOUR_APP_NAME = settings.YOUR_APP_NAME

logger = logging.getLogger(__name__)

def call_openrouter_api(prompt: str, model: str = None) -> str:
    """
    Calls the OpenRouter API to get a completion for the given prompt.

    Args:
        prompt: The input prompt for the LLM.
        model: The model to use (default: value from config OPENROUTER_MODEL).

    Returns:
        The content of the LLM's response.

    Raises:
        HTTPException: If the API key is missing or the API call fails.
    """
    if not OPENROUTER_API_KEY:
        print("Error: OPENROUTER_API_KEY environment variable not set.")
        raise HTTPException(status_code=500, detail="OpenRouter API key not configured.")

    if model is None:
        model = OPENROUTER_MODEL

    try:
        response = requests.post(
            url=OPENROUTER_API_URL,
            headers={
                "Authorization": f"Bearer {OPENROUTER_API_KEY}",
                "HTTP-Referer": YOUR_SITE_URL, # Optional, for OpenRouter analytics
                "X-Title": YOUR_APP_NAME, # Optional, for OpenRouter analytics
                "Content-Type": "application/json"
            },
            json={
                "model": model,
                "messages": [
                    {"role": "system", "content": "You are a helpful assistant summarizing technical support information. Provide a concise summary or key action points based on the provided context."},
                    {"role": "user", "content": prompt}
                ]
            }
        )

        response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)

        data = response.json()

        if data.get("choices") and len(data["choices"]) > 0:
            # Extract the message content
            message_content = data["choices"][0].get("message", {}).get("content", "")
            return message_content.strip()
        else:
            print(f"Warning: No choices returned from OpenRouter API. Response: {data}")
            return "LLM did not provide a summary."

    except requests.exceptions.RequestException as e:
        print(f"Error calling OpenRouter API: {e}")
        # Check for specific status codes if needed, e.g., 401 for auth errors
        status_code = 500
        detail = f"Failed to communicate with OpenRouter API: {e}"
        if e.response is not None:
            status_code = e.response.status_code
            try:
                error_detail = e.response.json().get('error', {}).get('message', str(e))
                detail = f"OpenRouter API Error ({status_code}): {error_detail}"
            except ValueError: # Handle cases where response is not JSON
                detail = f"OpenRouter API Error ({status_code}): {e.response.text}"

        raise HTTPException(status_code=status_code, detail=detail)
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        raise HTTPException(status_code=500, detail=f"An unexpected error occurred while processing LLM request: {e}")


def generate_summary_from_results(results: list) -> str:
    """
    Generates a prompt from the top search results and calls the LLM.

    Args:
        results: A list of search result dictionaries.

    Returns:
        The summary generated by the LLM.
    """
    if not results:
        return ""

    # Take top N results (configurable, file-backed)
    top_results = results[:settings.LLM_TOP_RESULTS]

    logger.info(f"Top results: {top_results}")

    # Construct prompt
    prompt_context = "Based on the following top search results, please provide key action points:\n\n"
    for i, result in enumerate(top_results):
        title = result.get('title', 'N/A')
        source_type = result.get('type', 'Unknown').replace('_', ' ').title()
        description = result.get('description', '')[:2000]
        similarity_score = result.get('similarity_score', None)
        root_cause = result.get('root_cause') or (result.get('msg_data', {}) or {}).get('root_cause')
        solution = result.get('solution') or (result.get('msg_data', {}) or {}).get('solution')

        prompt_context += f"Result {i+1} (Type: {source_type}):\n"
        prompt_context += f"Title: {title}\n"
        if similarity_score is not None:
            prompt_context += f"Similarity Score: {similarity_score:.2f}\n"
        prompt_context += f"Description: {description}\n"

        # Add root cause and solution if present
        if root_cause:
            prompt_context += f"Root Cause: {root_cause}\n"
        if solution:
            prompt_context += f"Solution: {solution}\n"

        # Add message data if present
        msg_data = result.get('msg_data')
        if msg_data:
            prompt_context += f"Sender: {msg_data.get('sender', 'N/A')}\n"
            prompt_context += f"Received Date: {msg_data.get('received_date', 'N/A')}\n"
            prompt_context += f"Jira URL: {msg_data.get('jira_url', 'N/A')}\n"
            prompt_context += f"Body: {msg_data.get('body', '')[:500]}\n"

        prompt_context += "\n"

    try:
        summary = call_openrouter_api(prompt_context)
        return summary
    except HTTPException as e:
        # Log the error or handle it as needed, maybe return an error message
        print(f"LLM Service Error: {e.detail}")
        return f"Error generating summary: {e.detail}"
    except Exception as e:
        print(f"Unexpected error in LLM generation: {e}")
        return "Error: Could not generate summary due to an unexpected issue."

# Example usage (for testing)
if __name__ == "__main__":
    # Mock results for testing
    mock_results = [
        {
            "type": "vector_issue",
            "title": "Login fails after password reset",
            "description": "User reports being unable to log in after successfully resetting their password. Error message 'Invalid credentials' displayed. Checked logs, password hash updated correctly. Suspect cache issue on client side.",
            "similarity_score": 0.95,
            "root_cause": "Cache issue on client side",
            "solution": "Clear cache and cookies"
        },
        {
            "type": "confluence",
            "title": "Troubleshooting Login Issues",
            "description": "Common login problems include incorrect username/password, locked accounts, and browser cache/cookies. Steps to resolve: 1. Verify credentials. 2. Try incognito mode. 3. Clear cache and cookies. 4. Contact support if issues persist.",
            "similarity_score": 0.88,
            "url": "https://confluence.example.com/display/KB/Troubleshooting+Login+Issues"
        },
        {
            "type": "stackoverflow",
            "title": "Flask login not working after password change",
            "description": "My Flask app uses Flask-Login. When a user changes their password, they can't log back in immediately. I'm updating the password hash in the database correctly. Is there a session issue?",
            "similarity_score": 0.85,
            "url": "https://stackoverflow.com/questions/12345/flask-login-not-working"
        }
    ]

    print("--- Generating Summary --- ")
    summary = generate_summary_from_results(mock_results)
    print("\n--- LLM Summary --- ")
    print(summary)